# 36. 얼굴표정으로 드론 조종하기
## deepface 설치하기
* deepface는 Keras와 TensorFlow를 바탕으로 만든 얼굴 인식 라이브러리입니다. 
* TensorFlow는 머신 러닝을 위한 오픈소스 소프트웨어입니다. C++ 언어로 작성되었고, 파이썬(Python) 응용 프로그래밍 인터페이스(API)를 제공합니다. Tensorflow와 OpenCV의 영상인식을 융합해서 사용할 수 있습니다.
* https://www.tensorflow.org/install/pip?hl=ko#virtual-environment-install 에서 사용할 수 있는 파이썬 버전을 확인합니다.
* 파이썬 3.9버전을 다운로드 받아서 사용하겠습니다. 
* 파이썬 버전, 패키지 버전이 잘 맞지 않으면 오류가 납니다.
* 시스템 속성 > 고급 > 환경변수에서 환경변수를 확인합니다.
* 아래 메뉴에서 Path를 확인합니다.
* 현재 파이썬 3.9가 환경변수에 저장되어 있다면 ```pip install tensorflow```로 설치합니다.
* 그렇지 않다면 ```py -버전 -m pip install 패키지```로 파이썬 버전에 맞게 패키지를 설치할 수 있습니다.
```
py -3.9 -m pip install tensorflow
```
* tensorflow를 설치했다면 deepface를 설치합니다.
* 설치된 패키지는 파이썬 폴더의 ```Lib/site-packages```에서 확인할 수 있습니다.
* 얼굴에서 감정, 나이, 성별 등을 확인하기 위해서 관련된 데이터 파일을 다운로드 받아야 합니다.
* https://github.com/serengil/deepface_models/releases/ 에서 다운로드 받습니다.
![image](https://user-images.githubusercontent.com/76088532/146551611-23a96bda-203e-45ab-a449-dd5f0baeb30f.png)

* 어느 경로에 데이터와 관련된 파일을 다운로드 받아야 하는지 확인합니다. 
* ```.deepface\weights``` 안에 파일을 다운로드 받습니다.
```
From: https://github.com/serengil/deepface_models/releases/download/v1.0/age_model_weights.h5
To: C:\Users\USER\.deepface\weights\age_model_weights.h5
```

## deepface로 감정 읽기
* 다양한 표정의 사진을 다운로드 받습니다.
* https://github.com/serengil/deepface/tree/master/tests/dataset 에서 원하는 사진을 다운로드 받아서 사용할 수 있습니다.
* ```from deepface import DeepFace```로 모듈을 가져옵니다.
* cv.imread로 그림을 읽습니다.
* DeepFace.analyze로 사진을 분석합니다.
* ```enforce_detection=False``` 옵션을 설정합니다.
* 결과는 딕셔너리 자료형입니다. print()로 확인합니다.
* ```dominant_emotion```가 사진에서 볼 수 있는 두드러진 감정입니다. 
* ```actions = ['age', 'gender', 'race', 'emotion']```로 분석하고 싶은 것을 옵션으로 넣을 수 있습니다.
```python
import cv2 as cv
from deepface import DeepFace

img = cv.imread("happy.png")
result = DeepFace.analyze(img, enforce_detection=False)
print(result['dominant_emotion'])
```

```python
import cv2 as cv
from deepface import DeepFace

img = cv.imread("happy.png")
result = DeepFace.analyze(img, actions = ['emotion'], enforce_detection=False)
print(result['dominant_emotion'])
```

* 사진에서 얼굴을 표시하고 감정을 글씨로 나타낼 수 있습니다.
```python
import cv2 as cv
from deepface import DeepFace

img = cv.imread("happy.png")
result = DeepFace.analyze(img, actions = ['emotion'], enforce_detection=False)

face_cascade = cv.CascadeClassifier()
face_cascade.load(r'C:\opencv\haarcascade_frontalface_default.xml')
font = cv.FONT_HERSHEY_DUPLEX

grayframe = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
grayframe = cv.equalizeHist(grayframe)
faces = face_cascade.detectMultiScale(grayframe, 1.1, 4)
for (x,y,w,h) in faces:
    cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)
    cv.putText(img, result['dominant_emotion'], (x, y-10), font, 0.5, (255,0,0))
cv.imshow("Emotion", img)
```

* 영상에서 얼굴을 표시하고 감정을 글씨로 나타낼 수 있습니다.
* ```if key == 27:```는 ESC키를 눌렀을 때입니다.
```python
import cv2 as cv
from deepface import DeepFace

capture = cv.VideoCapture(0)
capture.set(cv.CAP_PROP_FRAME_WIDTH, 640)
capture.set(cv.CAP_PROP_FRAME_HEIGHT, 480)
face_cascade = cv.CascadeClassifier()
face_cascade.load(r'C:\opencv\haarcascade_frontalface_default.xml')
font = cv.FONT_HERSHEY_DUPLEX

while True:
    ret, frame = capture.read()
    result = DeepFace.analyze(frame, actions = ['emotion'], enforce_detection=False)
    frame = cv.flip(frame, 1)
    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    grayframe = cv.equalizeHist(grayframe)
    faces = face_cascade.detectMultiScale(grayframe, 1.1, 3, 0, (30, 30))    
    for (x,y,w,h) in faces:
        cv.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),3)
        cv.putText(frame, result['dominant_emotion'], (x, y-10), font, 0.5, (255,0,0))
    cv.imshow("Emotion", frame)
    key = cv.waitKey(1)
    if key == 27:
        break

capture.release()
cv.destroyAllWindows()
```

* 표정에 따라서 이륙하고 착륙하는 프로그램을 만들 수 있습니다.
